#!/usr/bin/env python3
"""
Debug script to see what code is actually being generated by the models.
"""

import os
import sys
import torch
from pathlib import Path

# Add src to path for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, 'src')
sys.path.insert(0, src_path)

from data import CadQueryDataset
from models.baseline import create_baseline_model
from models.enhanced import create_enhanced_model


def debug_predictions():
    """Debug what code is being generated."""
    print("üîç Debugging Model Predictions...")
    print("=" * 50)
    
    # Load test dataset
    test_dataset = CadQueryDataset(split='test', max_samples=5)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Load trained models
    print("Loading trained models...")
    try:
        # Load baseline model
        baseline_model = create_baseline_model()
        baseline_checkpoint = torch.load('checkpoints/baseline/checkpoint_epoch_3.pt', map_location=device)
        baseline_model.load_state_dict(baseline_checkpoint['model_state_dict'])
        baseline_model.to(device).eval()
        print("‚úÖ Baseline model loaded")
        
        # Load enhanced model
        enhanced_model = create_enhanced_model(
            use_grammar=True,
            use_execution_guidance=True,
            use_reranking=True,
            best_of_n=6
        )
        enhanced_checkpoint = torch.load('checkpoints/enhanced/enhanced_checkpoint_epoch_3.pt', map_location=device)
        enhanced_model.load_state_dict(enhanced_checkpoint['model_state_dict'])
        enhanced_model.to(device).eval()
        print("‚úÖ Enhanced model loaded")
        
    except Exception as e:
        print(f"Error loading models: {e}")
        return
    
    # Test on 3 samples
    for i in range(3):
        try:
            sample = test_dataset.get_sample(i)
            print(f"\n{'='*60}")
            print(f"SAMPLE {i+1}")
            print(f"{'='*60}")
            
            print(f"Original code length: {len(sample['code'])}")
            print(f"Original code (first 200 chars):")
            print(sample['code'][:200])
            print("...")
            
            # Prepare image
            image_tensor = test_dataset.image_processor.process_image(sample['image']).unsqueeze(0).to(device)
            
            # Generate with baseline model
            print(f"\n--- BASELINE MODEL PREDICTION ---")
            with torch.no_grad():
                baseline_generated = baseline_model.generate_text(
                    image_tensor, 
                    max_length=512,
                    num_beams=4
                )
                baseline_code = baseline_generated[0]
                print(f"Generated code length: {len(baseline_code)}")
                print(f"Generated code:")
                print(baseline_code)
                print(f"Code starts with 'import': {baseline_code.startswith('import')}")
                print(f"Code contains 'cadquery': {'cadquery' in baseline_code.lower()}")
                print(f"Code contains 'result': {'result' in baseline_code}")
            
            # Generate with enhanced model
            print(f"\n--- ENHANCED MODEL PREDICTION ---")
            with torch.no_grad():
                enhanced_generated = enhanced_model.generate_text(
                    image_tensor,
                    max_length=512,
                    num_beams=4
                )
                enhanced_code = enhanced_generated[0]
                print(f"Generated code length: {len(enhanced_code)}")
                print(f"Generated code:")
                print(enhanced_code)
                print(f"Code starts with 'import': {enhanced_code.startswith('import')}")
                print(f"Code contains 'cadquery': {'cadquery' in enhanced_code.lower()}")
                print(f"Code contains 'result': {'result' in enhanced_code}")
            
            # Compare
            print(f"\n--- COMPARISON ---")
            print(f"Baseline vs Enhanced length: {len(baseline_code)} vs {len(enhanced_code)}")
            print(f"Same code: {baseline_code == enhanced_code}")
            
        except Exception as e:
            print(f"Error processing sample {i}: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    print(f"\n{'='*60}")
    print("DEBUG COMPLETED")
    print(f"{'='*60}")


if __name__ == "__main__":
    debug_predictions()
